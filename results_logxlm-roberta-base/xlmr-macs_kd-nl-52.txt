Tue Dec 27 19:44:29 2022
Exp setting: xlmr for XABSA (BIEOS) | 0.6312 | en -> nl in macs_kd setting.
Model is saved in outputDIRxlm-roberta-base/xlmr-en-nl-macs_kd-52
Train setting: bs=16, lr=4e-05, total_steps=2000 (Start eval from 1000)

* Results *:  Dev  /  Test  
Step-1000:
micro_f1: 0.7525 / 0.6145     precision: 0.7975 / 0.6414     recall  : 0.7123 / 0.5898     eval_loss: 0.1341 / 0.1517     
Step-1100:
micro_f1: 0.7551 / 0.6321     precision: 0.8069 / 0.6811     recall  : 0.7096 / 0.5898     eval_loss: 0.1373 / 0.1481     
Step-1200:
micro_f1: 0.7492 / 0.6351     precision: 0.8115 / 0.6810     recall  : 0.6959 / 0.5952     eval_loss: 0.1419 / 0.1435     
Step-1300:
micro_f1: 0.7707 / 0.6373     precision: 0.8078 / 0.6535     recall  : 0.7370 / 0.6220     eval_loss: 0.1297 / 0.1561     
Step-1400:
micro_f1: 0.7510 / 0.6380     precision: 0.7811 / 0.6609     recall  : 0.7233 / 0.6166     eval_loss: 0.1260 / 0.1516     
Step-1500:
micro_f1: 0.7619 / 0.6423     precision: 0.8049 / 0.6735     recall  : 0.7233 / 0.6139     eval_loss: 0.1277 / 0.1523     
Step-1600:
micro_f1: 0.7676 / 0.6323     precision: 0.8110 / 0.6580     recall  : 0.7288 / 0.6086     eval_loss: 0.1291 / 0.1505     
Step-1700:
micro_f1: 0.7734 / 0.6312     precision: 0.8171 / 0.6589     recall  : 0.7342 / 0.6059     eval_loss: 0.1281 / 0.1486     
Step-1800:
micro_f1: 0.7681 / 0.6483     precision: 0.7988 / 0.6648     recall  : 0.7397 / 0.6327     eval_loss: 0.1268 / 0.1441     
Step-1900:
micro_f1: 0.7663 / 0.6417     precision: 0.7982 / 0.6629     recall  : 0.7370 / 0.6220     eval_loss: 0.1266 / 0.1472     


