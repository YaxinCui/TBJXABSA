Fri Dec 30 00:28:13 2022
Exp setting: mbert for XABSA (BIO) | 0.5123 | en -> ru in macs_kd setting.
Model is saved in outputDIR/bert-base-multilingual-cased-2/mbert-en-ru-macs_kd-42
Train setting: bs=16, lr=4e-05, total_steps=2577 (Start eval from 1289)

* Results *:  Dev  /  Test  
Step-2400:
micro_f1: 0.7076 / 0.5127     precision: 0.7057 / 0.4965     recall  : 0.7096 / 0.5302     eval_loss: 0.1393 / 0.1925     
Step-2500:
micro_f1: 0.7105 / 0.5123     precision: 0.7115 / 0.4995     recall  : 0.7096 / 0.5259     eval_loss: 0.1400 / 0.1921     
Step-1300:
micro_f1: 0.6840 / 0.5097     precision: 0.6860 / 0.4936     recall  : 0.6822 / 0.5270     eval_loss: 0.1515 / 0.2021     
Step-1400:
micro_f1: 0.6872 / 0.5101     precision: 0.7040 / 0.5145     recall  : 0.6712 / 0.5058     eval_loss: 0.1528 / 0.2038     
Step-1900:
micro_f1: 0.7031 / 0.5060     precision: 0.7022 / 0.4859     recall  : 0.7041 / 0.5280     eval_loss: 0.1460 / 0.1972     
Step-2200:
micro_f1: 0.7095 / 0.5152     precision: 0.7096 / 0.5030     recall  : 0.7096 / 0.5280     eval_loss: 0.1402 / 0.1928     
Step-2300:
micro_f1: 0.7103 / 0.5143     precision: 0.7084 / 0.4995     recall  : 0.7123 / 0.5302     eval_loss: 0.1391 / 0.1928     
Step-1700:
micro_f1: 0.7039 / 0.5213     precision: 0.7011 / 0.4971     recall  : 0.7068 / 0.5481     eval_loss: 0.1394 / 0.1974     
Step-1800:
micro_f1: 0.7052 / 0.5156     precision: 0.7091 / 0.5010     recall  : 0.7014 / 0.5312     eval_loss: 0.1355 / 0.1880     
Step-1500:
micro_f1: 0.7018 / 0.5066     precision: 0.6944 / 0.4887     recall  : 0.7096 / 0.5259     eval_loss: 0.1453 / 0.2035     
Step-2100:
micro_f1: 0.7042 / 0.5170     precision: 0.7072 / 0.5056     recall  : 0.7014 / 0.5291     eval_loss: 0.1430 / 0.1937     
Step-2000:
micro_f1: 0.7066 / 0.5134     precision: 0.7038 / 0.4941     recall  : 0.7096 / 0.5344     eval_loss: 0.1387 / 0.1904     
Step-1600:
micro_f1: 0.6975 / 0.5091     precision: 0.6938 / 0.4888     recall  : 0.7014 / 0.5312     eval_loss: 0.1352 / 0.1923     


