Fri Dec 30 03:28:56 2022
Exp setting: mbert for XABSA (BIO) | 0.5535 | en -> nl in macs_kd setting.
Model is saved in outputDIR/bert-base-multilingual-cased-2/mbert-en-nl-macs_kd-42
Train setting: bs=16, lr=4e-05, total_steps=2577 (Start eval from 1289)

* Results *:  Dev  /  Test  
Step-2400:
micro_f1: 0.7076 / 0.5470     precision: 0.7057 / 0.5274     recall  : 0.7096 / 0.5684     eval_loss: 0.1393 / 0.1742     
Step-2500:
micro_f1: 0.7105 / 0.5535     precision: 0.7115 / 0.5394     recall  : 0.7096 / 0.5684     eval_loss: 0.1400 / 0.1738     
Step-1300:
micro_f1: 0.6840 / 0.5505     precision: 0.6860 / 0.5203     recall  : 0.6822 / 0.5845     eval_loss: 0.1515 / 0.1769     
Step-1400:
micro_f1: 0.6872 / 0.5548     precision: 0.7040 / 0.5469     recall  : 0.6712 / 0.5630     eval_loss: 0.1528 / 0.1733     
Step-1900:
micro_f1: 0.7031 / 0.5454     precision: 0.7022 / 0.5155     recall  : 0.7041 / 0.5791     eval_loss: 0.1460 / 0.1745     
Step-2200:
micro_f1: 0.7095 / 0.5452     precision: 0.7096 / 0.5333     recall  : 0.7096 / 0.5576     eval_loss: 0.1402 / 0.1723     
Step-2300:
micro_f1: 0.7103 / 0.5591     precision: 0.7084 / 0.5429     recall  : 0.7123 / 0.5764     eval_loss: 0.1391 / 0.1756     
Step-1700:
micro_f1: 0.7039 / 0.5281     precision: 0.7011 / 0.4953     recall  : 0.7068 / 0.5657     eval_loss: 0.1394 / 0.1801     
Step-1800:
micro_f1: 0.7052 / 0.5401     precision: 0.7091 / 0.5146     recall  : 0.7014 / 0.5684     eval_loss: 0.1355 / 0.1697     
Step-1500:
micro_f1: 0.7018 / 0.5496     precision: 0.6944 / 0.5299     recall  : 0.7096 / 0.5710     eval_loss: 0.1453 / 0.1818     
Step-2100:
micro_f1: 0.7042 / 0.5564     precision: 0.7072 / 0.5450     recall  : 0.7014 / 0.5684     eval_loss: 0.1430 / 0.1732     
Step-2000:
micro_f1: 0.7066 / 0.5544     precision: 0.7038 / 0.5363     recall  : 0.7096 / 0.5737     eval_loss: 0.1387 / 0.1687     
Step-1600:
micro_f1: 0.6975 / 0.5386     precision: 0.6938 / 0.5186     recall  : 0.7014 / 0.5603     eval_loss: 0.1352 / 0.1758     


