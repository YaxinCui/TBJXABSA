Fri Dec 30 05:32:07 2022
Exp setting: mbert for XABSA (BIO) | 0.6126 | en -> es in macs_kd setting.
Model is saved in outputDIR/bert-base-multilingual-cased-2/mbert-en-es-macs_kd-52
Train setting: bs=16, lr=4e-05, total_steps=2577 (Start eval from 1289)

* Results *:  Dev  /  Test  
Step-2400:
micro_f1: 0.7016 / 0.6153     precision: 0.6887 / 0.6082     recall  : 0.7151 / 0.6227     eval_loss: 0.1393 / 0.1910     
Step-2500:
micro_f1: 0.7060 / 0.6126     precision: 0.6921 / 0.6055     recall  : 0.7205 / 0.6199     eval_loss: 0.1383 / 0.1908     
Step-1300:
micro_f1: 0.7041 / 0.6156     precision: 0.7041 / 0.6287     recall  : 0.7041 / 0.6031     eval_loss: 0.1402 / 0.1871     
Step-1400:
micro_f1: 0.6912 / 0.5888     precision: 0.6894 / 0.5872     recall  : 0.6932 / 0.5905     eval_loss: 0.1436 / 0.1921     
Step-1900:
micro_f1: 0.6898 / 0.6100     precision: 0.6736 / 0.6058     recall  : 0.7068 / 0.6143     eval_loss: 0.1411 / 0.1878     
Step-2200:
micro_f1: 0.6968 / 0.6106     precision: 0.6770 / 0.6044     recall  : 0.7178 / 0.6171     eval_loss: 0.1414 / 0.1901     
Step-2300:
micro_f1: 0.6889 / 0.6116     precision: 0.6719 / 0.6049     recall  : 0.7068 / 0.6185     eval_loss: 0.1409 / 0.1888     
Step-1700:
micro_f1: 0.6887 / 0.6077     precision: 0.6925 / 0.6183     recall  : 0.6849 / 0.5975     eval_loss: 0.1416 / 0.1975     
Step-1800:
micro_f1: 0.6837 / 0.6061     precision: 0.6747 / 0.6036     recall  : 0.6932 / 0.6087     eval_loss: 0.1422 / 0.1877     
Step-1500:
micro_f1: 0.6998 / 0.6029     precision: 0.7067 / 0.6130     recall  : 0.6932 / 0.5933     eval_loss: 0.1372 / 0.1900     
Step-2100:
micro_f1: 0.6837 / 0.5952     precision: 0.6720 / 0.5944     recall  : 0.6959 / 0.5961     eval_loss: 0.1395 / 0.1895     
Step-2000:
micro_f1: 0.6947 / 0.6158     precision: 0.6882 / 0.6202     recall  : 0.7014 / 0.6115     eval_loss: 0.1381 / 0.1886     
Step-1600:
micro_f1: 0.7035 / 0.6025     precision: 0.6923 / 0.6122     recall  : 0.7151 / 0.5933     eval_loss: 0.1370 / 0.1892     


