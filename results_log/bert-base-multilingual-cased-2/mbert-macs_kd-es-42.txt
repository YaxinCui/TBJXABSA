Fri Dec 30 01:29:28 2022
Exp setting: mbert for XABSA (BIO) | 0.5783 | en -> es in macs_kd setting.
Model is saved in outputDIR/bert-base-multilingual-cased-2/mbert-en-es-macs_kd-42
Train setting: bs=16, lr=4e-05, total_steps=2577 (Start eval from 1289)

* Results *:  Dev  /  Test  
Step-2400:
micro_f1: 0.7076 / 0.5793     precision: 0.7057 / 0.5561     recall  : 0.7096 / 0.6045     eval_loss: 0.1393 / 0.2033     
Step-2500:
micro_f1: 0.7105 / 0.5783     precision: 0.7115 / 0.5580     recall  : 0.7096 / 0.6003     eval_loss: 0.1400 / 0.2026     
Step-1300:
micro_f1: 0.6840 / 0.5746     precision: 0.6860 / 0.5476     recall  : 0.6822 / 0.6045     eval_loss: 0.1515 / 0.2084     
Step-1400:
micro_f1: 0.6872 / 0.5866     precision: 0.7040 / 0.5802     recall  : 0.6712 / 0.5933     eval_loss: 0.1528 / 0.2014     
Step-1900:
micro_f1: 0.7031 / 0.5822     precision: 0.7022 / 0.5603     recall  : 0.7041 / 0.6059     eval_loss: 0.1460 / 0.2025     
Step-2200:
micro_f1: 0.7095 / 0.5788     precision: 0.7096 / 0.5638     recall  : 0.7096 / 0.5947     eval_loss: 0.1402 / 0.2028     
Step-2300:
micro_f1: 0.7103 / 0.5777     precision: 0.7084 / 0.5557     recall  : 0.7123 / 0.6017     eval_loss: 0.1391 / 0.2049     
Step-1700:
micro_f1: 0.7039 / 0.5783     precision: 0.7011 / 0.5453     recall  : 0.7068 / 0.6157     eval_loss: 0.1394 / 0.2087     
Step-1800:
micro_f1: 0.7052 / 0.5887     precision: 0.7091 / 0.5652     recall  : 0.7014 / 0.6143     eval_loss: 0.1355 / 0.1923     
Step-1500:
micro_f1: 0.7018 / 0.5843     precision: 0.6944 / 0.5471     recall  : 0.7096 / 0.6269     eval_loss: 0.1453 / 0.2080     
Step-2100:
micro_f1: 0.7042 / 0.5784     precision: 0.7072 / 0.5605     recall  : 0.7014 / 0.5975     eval_loss: 0.1430 / 0.2049     
Step-2000:
micro_f1: 0.7066 / 0.5708     precision: 0.7038 / 0.5501     recall  : 0.7096 / 0.5933     eval_loss: 0.1387 / 0.1994     
Step-1600:
micro_f1: 0.6975 / 0.5818     precision: 0.6938 / 0.5539     recall  : 0.7014 / 0.6129     eval_loss: 0.1352 / 0.2007     


