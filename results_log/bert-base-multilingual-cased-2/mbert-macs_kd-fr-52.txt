Fri Dec 30 06:31:44 2022
Exp setting: mbert for XABSA (BIO) | 0.5076 | en -> fr in macs_kd setting.
Model is saved in outputDIR/bert-base-multilingual-cased-2/mbert-en-fr-macs_kd-52
Train setting: bs=16, lr=4e-05, total_steps=2577 (Start eval from 1289)

* Results *:  Dev  /  Test  
Step-2400:
micro_f1: 0.7016 / 0.5020     precision: 0.6887 / 0.5271     recall  : 0.7151 / 0.4792     eval_loss: 0.1393 / 0.2098     
Step-2500:
micro_f1: 0.7060 / 0.5076     precision: 0.6921 / 0.5321     recall  : 0.7205 / 0.4854     eval_loss: 0.1383 / 0.2087     
Step-1300:
micro_f1: 0.7041 / 0.5033     precision: 0.7041 / 0.5417     recall  : 0.7041 / 0.4700     eval_loss: 0.1402 / 0.2069     
Step-1400:
micro_f1: 0.6912 / 0.5160     precision: 0.6894 / 0.5550     recall  : 0.6932 / 0.4823     eval_loss: 0.1436 / 0.2108     
Step-1900:
micro_f1: 0.6898 / 0.5175     precision: 0.6736 / 0.5373     recall  : 0.7068 / 0.4992     eval_loss: 0.1411 / 0.2058     
Step-2200:
micro_f1: 0.6968 / 0.5081     precision: 0.6770 / 0.5369     recall  : 0.7178 / 0.4823     eval_loss: 0.1414 / 0.2099     
Step-2300:
micro_f1: 0.6889 / 0.5109     precision: 0.6719 / 0.5414     recall  : 0.7068 / 0.4838     eval_loss: 0.1409 / 0.2077     
Step-1700:
micro_f1: 0.6887 / 0.5037     precision: 0.6925 / 0.5469     recall  : 0.6849 / 0.4669     eval_loss: 0.1416 / 0.2169     
Step-1800:
micro_f1: 0.6837 / 0.5157     precision: 0.6747 / 0.5425     recall  : 0.6932 / 0.4915     eval_loss: 0.1422 / 0.2095     
Step-1500:
micro_f1: 0.6998 / 0.5145     precision: 0.7067 / 0.5576     recall  : 0.6932 / 0.4777     eval_loss: 0.1372 / 0.2098     
Step-2100:
micro_f1: 0.6837 / 0.5004     precision: 0.6720 / 0.5254     recall  : 0.6959 / 0.4777     eval_loss: 0.1395 / 0.2139     
Step-2000:
micro_f1: 0.6947 / 0.5081     precision: 0.6882 / 0.5409     recall  : 0.7014 / 0.4792     eval_loss: 0.1381 / 0.2083     
Step-1600:
micro_f1: 0.7035 / 0.5119     precision: 0.6923 / 0.5516     recall  : 0.7151 / 0.4777     eval_loss: 0.1370 / 0.2100     


