Fri Dec 30 04:30:52 2022
Exp setting: mbert for XABSA (BIO) | 0.5358 | en -> ru in macs_kd setting.
Model is saved in outputDIR/bert-base-multilingual-cased-2/mbert-en-ru-macs_kd-52
Train setting: bs=16, lr=4e-05, total_steps=2577 (Start eval from 1289)

* Results *:  Dev  /  Test  
Step-2400:
micro_f1: 0.7016 / 0.5411     precision: 0.6887 / 0.5123     recall  : 0.7151 / 0.5735     eval_loss: 0.1393 / 0.1955     
Step-2500:
micro_f1: 0.7060 / 0.5358     precision: 0.6921 / 0.5061     recall  : 0.7205 / 0.5693     eval_loss: 0.1383 / 0.1964     
Step-1300:
micro_f1: 0.7041 / 0.5373     precision: 0.7041 / 0.5140     recall  : 0.7041 / 0.5630     eval_loss: 0.1402 / 0.1958     
Step-1400:
micro_f1: 0.6912 / 0.5364     precision: 0.6894 / 0.5204     recall  : 0.6932 / 0.5534     eval_loss: 0.1436 / 0.1977     
Step-1900:
micro_f1: 0.6898 / 0.5387     precision: 0.6736 / 0.5104     recall  : 0.7068 / 0.5704     eval_loss: 0.1411 / 0.1966     
Step-2200:
micro_f1: 0.6968 / 0.5405     precision: 0.6770 / 0.5103     recall  : 0.7178 / 0.5746     eval_loss: 0.1414 / 0.1980     
Step-2300:
micro_f1: 0.6889 / 0.5414     precision: 0.6719 / 0.5128     recall  : 0.7068 / 0.5735     eval_loss: 0.1409 / 0.1966     
Step-1700:
micro_f1: 0.6887 / 0.5412     precision: 0.6925 / 0.5276     recall  : 0.6849 / 0.5556     eval_loss: 0.1416 / 0.1967     
Step-1800:
micro_f1: 0.6837 / 0.5382     precision: 0.6747 / 0.5192     recall  : 0.6932 / 0.5587     eval_loss: 0.1422 / 0.1930     
Step-1500:
micro_f1: 0.6998 / 0.5457     precision: 0.7067 / 0.5363     recall  : 0.6932 / 0.5556     eval_loss: 0.1372 / 0.1938     
Step-2100:
micro_f1: 0.6837 / 0.5479     precision: 0.6720 / 0.5210     recall  : 0.6959 / 0.5778     eval_loss: 0.1395 / 0.1926     
Step-2000:
micro_f1: 0.6947 / 0.5387     precision: 0.6882 / 0.5202     recall  : 0.7014 / 0.5587     eval_loss: 0.1381 / 0.1922     
Step-1600:
micro_f1: 0.7035 / 0.5422     precision: 0.6923 / 0.5168     recall  : 0.7151 / 0.5704     eval_loss: 0.1370 / 0.1963     


